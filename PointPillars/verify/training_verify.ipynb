{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "import data_process\n",
    "import open3d as o3d\n",
    "import copy\n",
    "import numba\n",
    "import random\n",
    "from ops import Voxelization, nms_cuda\n",
    "import torch\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from models.pointpillars import PointPillars, PFNLayer\n",
    "import data_process\n",
    "import data_augment\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from models.gpu_mem_track import MemTracker\n",
    "\n",
    "import inspect\n",
    "from models.losses import Losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_root = '/media/chris/Workspace/Dataset/3d-object-detection-for-autonomous-vehicles/kitti_format/'\n",
    "# dataset_root = '/media/chris/Workspace/Dataset/kitti'\n",
    "dataset_root = '/media/chris/Workspace/Dataset/3d-object-detection-one_scene/kitti_format'\n",
    "# dataset_root = '/media/chris/Workspace/Dataset/lyft'\n",
    "\n",
    "# dataset_root = '/media/chris/胖虎的硬盘/kitti_format'\n",
    "identifier = 'train'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取pkl文件里的数据\n",
    "# data_content = data_process.read_pickle(os.path.join(dataset_root,f'lyft_infos_{identifier}.pkl'))\n",
    "# database_content = data_process.read_pickle(os.path.join(dataset_root,f'lyft_dbinfos_train.pkl'))\n",
    "torch.cuda.empty_cache()\n",
    "num_classes = 5\n",
    "batch_size = 6\n",
    "num_workers = 8"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set the random seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the random seed\n",
    "random.seed(2023)\n",
    "np.random.seed(2023)\n",
    "torch.manual_seed(2023)\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda:0\")\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True       #用cudnn加速\n",
    "    torch.cuda.manual_seed_all(2023)\n",
    "else:\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 获取数据增强后的数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 自定义collate_batch用于torch的Dataloader\n",
    "def collate_batch(data):\n",
    "    batched_pointcloud_list = []\n",
    "    batched_gt_3d_bboxes_list = []\n",
    "    batched_labels_list= []\n",
    "    batched_names_list = []\n",
    "    batched_difficulty_list = []\n",
    "    batched_img_list = []\n",
    "    batched_calibration_list = []\n",
    "    for data_dict in data:\n",
    "        cur_pc = data_dict['pc']\n",
    "        cur_image_info = data_dict['img']\n",
    "        cur_gt_labels = data_dict['gt_labels']\n",
    "        cur_gt_names = data_dict['gt_names']\n",
    "        cur_gt_bboxes_3d = data_dict['gt_bboxes_3d']\n",
    "        cur_difficulty = data_dict['difficulty']\n",
    "        cur_calbi_info = data_dict['calib']\n",
    "\n",
    "        batched_pointcloud_list.append(torch.from_numpy(cur_pc))\n",
    "        batched_gt_3d_bboxes_list.append(torch.from_numpy(cur_gt_bboxes_3d))\n",
    "        batched_labels_list.append(torch.from_numpy(cur_gt_labels))\n",
    "        batched_names_list.append(cur_gt_names) # List(str)\n",
    "        batched_difficulty_list.append(torch.from_numpy(cur_difficulty))\n",
    "        batched_img_list.append(cur_image_info)\n",
    "        batched_calibration_list.append(cur_calbi_info)\n",
    "    \n",
    "    rt_data_dict = dict(\n",
    "        batched_pts=batched_pointcloud_list,\n",
    "        batched_img_info=batched_img_list,\n",
    "        batched_labels=batched_labels_list,\n",
    "        batched_names=batched_names_list,\n",
    "        batched_gt_bboxes=batched_gt_3d_bboxes_list,\n",
    "        batched_difficulty=batched_difficulty_list,\n",
    "        batched_calib_info=batched_calibration_list\n",
    "    )\n",
    "\n",
    "    return rt_data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获取数据增强后的数据\n",
    "train_data = data_augment.DataSet(dataset_root=dataset_root,identifier='train')\n",
    "val_data = data_augment.DataSet(dataset_root=dataset_root,identifier='val')\n",
    "\n",
    "# print(train_data[0])\n",
    "\n",
    "train_dataloader = DataLoader(dataset=val_data, batch_size=batch_size, shuffle=True,num_workers=num_workers, drop_last=False, collate_fn=collate_batch)\n",
    "\n",
    "val_dataloader = DataLoader(dataset=val_data, batch_size=batch_size, shuffle=True,num_workers=num_workers, drop_last=False, collate_fn=collate_batch)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PointPillars Part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes=3\n",
    "\n",
    "pointpillars = PointPillars(num_classes=num_classes).cuda()\n",
    "\n",
    "criterion = Losses()\n",
    "\n",
    "max_iters = len(train_data) * 160\n",
    "\n",
    "\n",
    "max_num_points=32\n",
    "point_cloud_range=[0, -39.68, -3, 69.12, 39.68, 1]\n",
    "max_voxels=(16000, 40000)\n",
    "voxel_size=[0.16, 0.16, 4]\n",
    "\n",
    "learning_rate = 0.0003\n",
    "\n",
    "optimizer = torch.optim.AdamW(params=pointpillars.parameters(), \n",
    "                                  lr=learning_rate, \n",
    "                                  betas=(0.95, 0.99),\n",
    "                                  weight_decay=0.01)\n",
    "scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer,  \n",
    "                                                    max_lr=learning_rate*10, \n",
    "                                                    total_steps=max_iters, \n",
    "                                                    pct_start=0.4, \n",
    "                                                    anneal_strategy='cos',\n",
    "                                                    cycle_momentum=True, \n",
    "                                                    base_momentum=0.95*0.895, \n",
    "                                                    max_momentum=0.95,\n",
    "                                                    div_factor=10)\n",
    "\n",
    "import gc\n",
    "# del variables\n",
    "gc.collect()\n",
    "\n",
    "if hasattr(torch.cuda, 'empty_cache'):\n",
    "\ttorch.cuda.empty_cache()\n",
    "\n",
    "# 存储checkpoint的路径\n",
    "saved_ckpt_path = os.path.join('checkpoints')\n",
    "os.makedirs(saved_ckpt_path, exist_ok=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, criterion, scheduler, trainloader, device, valloader, max_epoch, ckpt_freq_epoch, saved_ckpt_path):\n",
    "\n",
    "    for epoch in range(max_epoch):\n",
    "        model = model.train()\n",
    "        for i, data_dict in enumerate(tqdm(trainloader)):\n",
    "            if torch.cuda.is_available():\n",
    "                # move tensors to cuda\n",
    "                for key in data_dict:\n",
    "                    for j, item in enumerate(data_dict[key]):\n",
    "                        if torch.is_tensor(item):\n",
    "                            data_dict[key][j] = data_dict[key][j].cuda()\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            # 获取当前的data\n",
    "            batched_pts = data_dict['batched_pts']\n",
    "            batched_gt_bboxes = data_dict['batched_gt_bboxes']\n",
    "            batched_labels = data_dict['batched_labels']\n",
    "            # batched_difficulty = data_dict['batched_difficulty']\n",
    "\n",
    "            # frame = inspect.currentframe()\n",
    "            # gpu_tracker = MemTracker(frame)     # 创建显存检测对象\n",
    "            # gpu_tracker.track()\n",
    "            # pillars, coors_batch, npoints_per_pillar, features, encoded_features, backbone_result = pointpillars(batched_pts=batched_pts)\n",
    "            pred_bbox_cls, pred_bbox_loc, bbox_dir_cls_pred, anchor_target_dict = model(batched_pts=batched_pts,mode='train',\n",
    "                                                                                            batched_gt_bboxes=batched_gt_bboxes, \n",
    "                                                                                            batched_gt_labels=batched_labels)\n",
    "            # print(\"bbox_cls_pred\",pred_bbox_cls.size())\n",
    "            # print(\"bbox_dir_cls_pred\",bbox_dir_cls_pred.size())\n",
    "            # print(\"bbox_pred\",pred_bbox_loc.size())\n",
    "            \n",
    "            # 预测的box的类别\n",
    "            pred_bbox_cls = pred_bbox_cls.permute(0, 2, 3, 1).reshape(-1, num_classes)\n",
    "            # 预测的box参数\n",
    "            pred_bbox_loc = pred_bbox_loc.permute(0, 2, 3, 1).reshape(-1, 7)\n",
    "            # 预测的box方向\n",
    "            bbox_dir_cls_pred = bbox_dir_cls_pred.permute(0, 2, 3, 1).reshape(-1, 2)\n",
    "\n",
    "            anchor_bbox_labels = anchor_target_dict['batched_labels'].reshape(-1)\n",
    "            anchor_label_weights = anchor_target_dict['batched_label_weights'].reshape(-1)\n",
    "            anchor_bbox_loc = anchor_target_dict['batched_bbox_reg'].reshape(-1, 7)\n",
    "            # batched_bbox_reg_weights = anchor_target_dict['batched_bbox_reg_weights'].reshape(-1)\n",
    "            anchor_dir_labels = anchor_target_dict['batched_dir_labels'].reshape(-1)\n",
    "            # batched_dir_labels_weights = anchor_target_dict['batched_dir_labels_weights'].reshape(-1)\n",
    "            \n",
    "            # 预测结果在范围内\n",
    "            pos_idx = (anchor_bbox_labels >= 0) & (anchor_bbox_labels < num_classes)\n",
    "            pred_bbox_loc = pred_bbox_loc[pos_idx]\n",
    "            anchor_bbox_loc = anchor_bbox_loc[pos_idx]\n",
    "\n",
    "            # 来自于ground truth\n",
    "            # delta_theta = sin(theta^gt-theta^anchor)      ------->        delta_theta = sin(theta^gt)*cos(theta^anchor) - cos(theta^gt)*sin(theta^anchor)\n",
    "            pred_bbox_loc[:,-1] = torch.sin(pred_bbox_loc[:, -1].clone()) * torch.cos(anchor_bbox_loc[:,-1].clone())\n",
    "            anchor_bbox_loc[:,-1] = torch.cos(pred_bbox_loc[:, -1].clone()) * torch.sin(anchor_bbox_loc[:,-1].clone())\n",
    "\n",
    "            pred_bbox_cls = pred_bbox_cls[anchor_label_weights > 0]\n",
    "            bbox_dir_cls_pred = bbox_dir_cls_pred[pos_idx]\n",
    "            anchor_dir_labels = anchor_dir_labels[pos_idx]\n",
    "\n",
    "            num_cls_pos = (anchor_bbox_labels < num_classes).sum()\n",
    "            anchor_bbox_labels[anchor_bbox_labels < 0] = num_classes\n",
    "            anchor_bbox_labels = anchor_bbox_labels[anchor_label_weights > 0]\n",
    "\n",
    "            loss = criterion(pred_bbox_cls=pred_bbox_cls,\n",
    "                                    pred_bbox_loc=pred_bbox_loc,\n",
    "                                    pred_bbox_dir=bbox_dir_cls_pred,\n",
    "                                    anchor_labels=anchor_bbox_labels, \n",
    "                                    num_cls_pos=num_cls_pos, \n",
    "                                    anchor_bbox_loc=anchor_bbox_loc, \n",
    "                                    anchor_bbox_dir_labels=anchor_dir_labels,\n",
    "                                    num_classes=num_classes)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "\n",
    "        # 20 epoch保存一次checkpoint\n",
    "        if (epoch + 1) % ckpt_freq_epoch == 0:\n",
    "            torch.save(pointpillars.state_dict(), os.path.join(saved_ckpt_path, f'epoch_{epoch+1}.pth'))\n",
    "\n",
    "        if epoch % 2 == 0:\n",
    "            continue\n",
    "        # If you pass in a validation dataloader then compute the validation loss\n",
    "        if not valloader is None:\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                for _, data_dict in valloader:\n",
    "                    if torch.cuda.is_available():\n",
    "                        # move tensors to cuda\n",
    "                        for key in data_dict:\n",
    "                            for j, item in enumerate(data_dict[key]):\n",
    "                                if torch.is_tensor(item):\n",
    "                                    data_dict[key][j] = data_dict[key][j].cuda()\n",
    "                    \n",
    "                    optimizer.zero_grad()\n",
    "                    # 获取当前的data\n",
    "                    batched_pts = data_dict['batched_pts']\n",
    "                    batched_gt_bboxes = data_dict['batched_gt_bboxes']\n",
    "                    batched_labels = data_dict['batched_labels']\n",
    "                    # batched_difficulty = data_dict['batched_difficulty']\n",
    "\n",
    "                    # frame = inspect.currentframe()\n",
    "                    # gpu_tracker = MemTracker(frame)     # 创建显存检测对象\n",
    "                    # gpu_tracker.track()\n",
    "                    # pillars, coors_batch, npoints_per_pillar, features, encoded_features, backbone_result = pointpillars(batched_pts=batched_pts)\n",
    "                    pred_bbox_cls, pred_bbox_loc, bbox_dir_cls_pred, anchor_target_dict = model(batched_pts=batched_pts,mode='train',\n",
    "                                                                                                    batched_gt_bboxes=batched_gt_bboxes, \n",
    "                                                                                                    batched_gt_labels=batched_labels)\n",
    "                    \n",
    "                    # 预测的box的类别\n",
    "                    pred_bbox_cls = pred_bbox_cls.permute(0, 2, 3, 1).reshape(-1, num_classes)\n",
    "                    # 预测的box参数\n",
    "                    pred_bbox_loc = pred_bbox_loc.permute(0, 2, 3, 1).reshape(-1, 7)\n",
    "                    # 预测的box方向\n",
    "                    bbox_dir_cls_pred = bbox_dir_cls_pred.permute(0, 2, 3, 1).reshape(-1, 2)\n",
    "\n",
    "                    anchor_bbox_labels = anchor_target_dict['batched_labels'].reshape(-1)\n",
    "                    anchor_label_weights = anchor_target_dict['batched_label_weights'].reshape(-1)\n",
    "                    anchor_bbox_loc = anchor_target_dict['batched_bbox_reg'].reshape(-1, 7)\n",
    "                    # batched_bbox_reg_weights = anchor_target_dict['batched_bbox_reg_weights'].reshape(-1)\n",
    "                    anchor_dir_labels = anchor_target_dict['batched_dir_labels'].reshape(-1)\n",
    "                    # batched_dir_labels_weights = anchor_target_dict['batched_dir_labels_weights'].reshape(-1)\n",
    "                    \n",
    "                    # 预测结果在范围内\n",
    "                    pos_idx = (anchor_bbox_labels >= 0) & (anchor_bbox_labels < num_classes)\n",
    "                    pred_bbox_loc = pred_bbox_loc[pos_idx]\n",
    "                    anchor_bbox_loc = anchor_bbox_loc[pos_idx]\n",
    "\n",
    "                    # 来自于ground truth\n",
    "                    # delta_theta = sin(theta^gt-theta^anchor)      ------->        delta_theta = sin(theta^gt)*cos(theta^anchor) - cos(theta^gt)*sin(theta^anchor)\n",
    "                    pred_bbox_loc[:,-1] = torch.sin(pred_bbox_loc[:, -1].clone()) * torch.cos(anchor_bbox_loc[:,-1].clone())\n",
    "                    anchor_bbox_loc[:,-1] = torch.cos(pred_bbox_loc[:, -1].clone()) * torch.sin(anchor_bbox_loc[:,-1].clone())\n",
    "\n",
    "                    pred_bbox_cls = pred_bbox_cls[anchor_label_weights > 0]\n",
    "                    bbox_dir_cls_pred = bbox_dir_cls_pred[pos_idx]\n",
    "                    anchor_dir_labels = anchor_dir_labels[pos_idx]\n",
    "\n",
    "                    num_cls_pos = (anchor_bbox_labels < num_classes).sum()\n",
    "                    anchor_bbox_labels[anchor_bbox_labels < 0] = num_classes\n",
    "                    anchor_bbox_labels = anchor_bbox_labels[anchor_label_weights > 0]\n",
    "\n",
    "                    loss = criterion(pred_bbox_cls=pred_bbox_cls,\n",
    "                                            pred_bbox_loc=pred_bbox_loc,\n",
    "                                            pred_bbox_dir=bbox_dir_cls_pred,\n",
    "                                            anchor_labels=anchor_bbox_labels, \n",
    "                                            num_cls_pos=num_cls_pos, \n",
    "                                            anchor_bbox_loc=anchor_bbox_loc, \n",
    "                                            anchor_bbox_dir_labels=anchor_dir_labels,\n",
    "                                            num_classes=num_classes)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if runtime has GPU use GPU\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda:0\")\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "print(\"Using device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # model, optimizer, criterion, scheduler, trainloader, device, valloader, max_epoch, ckpt_freq_epoch, saved_ckpt_path\n",
    "# model = train(model=pointpillars, \n",
    "#               optimizer=optimizer, \n",
    "#               criterion=criterion,\n",
    "#               scheduler=scheduler, \n",
    "#               trainloader=train_dataloader, \n",
    "#               device=device, \n",
    "#               valloader=val_dataloader, \n",
    "#               max_epoch=30,\n",
    "#               ckpt_freq_epoch=20,\n",
    "#               saved_ckpt_path=saved_ckpt_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_epoch = 1\n",
    "no_cuda = False\n",
    "for epoch in range(max_epoch):\n",
    "    print(epoch)\n",
    "    for i, data_dict in enumerate(tqdm(train_dataloader)):\n",
    "        if torch.cuda.is_available():\n",
    "            # move the tensors to the cuda\n",
    "            for key in data_dict:\n",
    "                for j, item in enumerate(data_dict[key]):\n",
    "                    if torch.is_tensor(item):\n",
    "                        data_dict[key][j] = data_dict[key][j].cuda()\n",
    "                        \n",
    "        optimizer.zero_grad()\n",
    "        # 获取当前的data\n",
    "        batched_pts = data_dict['batched_pts']\n",
    "        batched_gt_bboxes = data_dict['batched_gt_bboxes']\n",
    "        batched_labels = data_dict['batched_labels']\n",
    "        batched_difficulty = data_dict['batched_difficulty']\n",
    "\n",
    "        # frame = inspect.currentframe()\n",
    "        # gpu_tracker = MemTracker(frame)     # 创建显存检测对象\n",
    "        # gpu_tracker.track()\n",
    "        # pillars, coors_batch, npoints_per_pillar, features, encoded_features, backbone_result = pointpillars(batched_pts=batched_pts)\n",
    "        pred_bbox_cls, pred_bbox_loc, bbox_dir_cls_pred, anchor_target_dict = pointpillars(batched_pts=batched_pts,mode='train',\n",
    "                                                                                        batched_gt_bboxes=batched_gt_bboxes, \n",
    "                                                                                        batched_gt_labels=batched_labels)\n",
    "        # print(\"bbox_cls_pred\",pred_bbox_cls.size())\n",
    "        # print(\"bbox_dir_cls_pred\",bbox_dir_cls_pred.size())\n",
    "        # print(\"bbox_pred\",pred_bbox_loc.size())\n",
    "        \n",
    "        # 预测的box的类别\n",
    "        pred_bbox_cls = pred_bbox_cls.permute(0, 2, 3, 1).reshape(-1, num_classes)\n",
    "        # 预测的box参数\n",
    "        pred_bbox_loc = pred_bbox_loc.permute(0, 2, 3, 1).reshape(-1, 7)\n",
    "        # 预测的box方向\n",
    "        bbox_dir_cls_pred = bbox_dir_cls_pred.permute(0, 2, 3, 1).reshape(-1, 2)\n",
    "\n",
    "        anchor_bbox_labels = anchor_target_dict['batched_labels'].reshape(-1)\n",
    "        anchor_label_weights = anchor_target_dict['batched_label_weights'].reshape(-1)\n",
    "        anchor_bbox_loc = anchor_target_dict['batched_bbox_reg'].reshape(-1, 7)\n",
    "        # batched_bbox_reg_weights = anchor_target_dict['batched_bbox_reg_weights'].reshape(-1)\n",
    "        anchor_dir_labels = anchor_target_dict['batched_dir_labels'].reshape(-1)\n",
    "        # batched_dir_labels_weights = anchor_target_dict['batched_dir_labels_weights'].reshape(-1)\n",
    "        \n",
    "        # 预测结果在范围内\n",
    "        pos_idx = (anchor_bbox_labels >= 0) & (anchor_bbox_labels < num_classes)\n",
    "        pred_bbox_loc = pred_bbox_loc[pos_idx]\n",
    "        anchor_bbox_loc = anchor_bbox_loc[pos_idx]\n",
    "\n",
    "        # 来自于ground truth\n",
    "        # delta_theta = sin(theta^gt-theta^anchor)      ------->        delta_theta = sin(theta^gt)*cos(theta^anchor) - cos(theta^gt)*sin(theta^anchor)\n",
    "        pred_bbox_loc[:,-1] = torch.sin(pred_bbox_loc[:, -1].clone()) * torch.cos(anchor_bbox_loc[:,-1].clone())\n",
    "        anchor_bbox_loc[:,-1] = torch.cos(pred_bbox_loc[:, -1].clone()) * torch.sin(anchor_bbox_loc[:,-1].clone())\n",
    "\n",
    "        pred_bbox_cls = pred_bbox_cls[anchor_label_weights > 0]\n",
    "        bbox_dir_cls_pred = bbox_dir_cls_pred[pos_idx]\n",
    "        anchor_dir_labels = anchor_dir_labels[pos_idx]\n",
    "\n",
    "        num_cls_pos = (anchor_bbox_labels < num_classes).sum()\n",
    "        anchor_bbox_labels[anchor_bbox_labels < 0] = num_classes\n",
    "        anchor_bbox_labels = anchor_bbox_labels[anchor_label_weights > 0]\n",
    "\n",
    "        loss_dict = criterion(pred_bbox_cls=pred_bbox_cls,\n",
    "                                  pred_bbox_loc=pred_bbox_loc,\n",
    "                                  pred_bbox_dir=bbox_dir_cls_pred,\n",
    "                                  anchor_labels=anchor_bbox_labels, \n",
    "                                  num_cls_pos=num_cls_pos, \n",
    "                                  anchor_bbox_loc=anchor_bbox_loc, \n",
    "                                  anchor_bbox_dir_labels=anchor_dir_labels,\n",
    "                                  num_classes=num_classes)\n",
    "        loss = loss_dict['total_loss']\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        # gpu_tracker.track()\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pointPillars",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
